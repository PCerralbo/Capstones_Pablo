{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essentials\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_excel('train.xlsx') # Load the `train` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'comuns'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.party[15]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from stop_words import get_stop_words\n",
    "\n",
    "def special_char(text):\n",
    "    \"\"\"Retrieve the special characters\n",
    "    \"\"\"\n",
    "    return re.sub(r'\\W', ' ', text)\n",
    "\n",
    "def filter_single(text):\n",
    "    \"\"\"remove all single characters\n",
    "    \"\"\"\n",
    "    return re.sub(r'\\s+[a-zA-Z]\\s+', ' ', text)\n",
    "\n",
    "def filter_singleStart(text):\n",
    "    \"\"\"Remove single characters from the start\n",
    "    \"\"\"\n",
    "    return re.sub(r'\\^[a-zA-Z]\\s+', ' ', text)\n",
    "\n",
    "def filter_multiplespace(text):\n",
    "    \"\"\"Substituting multiple spaces with single space\n",
    "    \"\"\"\n",
    "    return re.sub(r'\\s+', ' ', text, flags=re.I)\n",
    "\n",
    "def stop_words():\n",
    "    \"\"\"Retrieve the stop words for vectorization -Feel free to modify this function\n",
    "    \"\"\"\n",
    "    return get_stop_words('es') + get_stop_words('ca') + get_stop_words('en')\n",
    "\n",
    "def filter_mentions(text):\n",
    "    \"\"\"Utility function to remove the mentions of a tweet\n",
    "    \"\"\"\n",
    "    return re.sub(\"@\\S+\", \"\", text)\n",
    "\n",
    "def filter_hashtags(text):\n",
    "    \"\"\"Utility function to remove the hashtags of a tweet\n",
    "    \"\"\"\n",
    "    return re.sub(\"#\\S+\", \"\", text)\n",
    "\n",
    "def filter_symb_hashtag(text):\n",
    "    \"\"\"Utility function to remove the hashtags symbol of a tweet\n",
    "    \"\"\"\n",
    "    return re.sub(\"#\", \"\", text)\n",
    "\n",
    "def filter_symb1(text):\n",
    "    \"\"\"Utility function to remove special characters of a tweet\n",
    "    \"\"\"\n",
    "    return re.sub(r'[(:+*?¬ø!¬°.,;-`\"\")]', \"\", text)\n",
    "\n",
    "#def translate_text(text):\n",
    "#    \"\"\"Utility function to translate the text of a tweet\n",
    "#    \"\"\"\n",
    "#    return translator.translate(text, dest='es').text\n",
    "\n",
    "def lower_text(text):\n",
    "    \"\"\"Utility function to lower text\n",
    "    \"\"\"\n",
    "    return text.lower()\n",
    "\n",
    "def eliminate_numbers(text):\n",
    "    \"\"\"Utility function to lower text\n",
    "    \"\"\"\n",
    "    return re.sub(r'\\w*\\d\\w*', '', text).strip()\n",
    "\n",
    "def eliminate_emojiis(text):\n",
    "    \"\"\"Utility to eliminate emojiis from the text\n",
    "    \"\"\"\n",
    "    em_pat=re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return  em_pat.sub(r'',text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Processing (1-3 fets)\n",
    "1) eliminate symbols :,?¬ø!';-\n",
    "2) eliminate single characters  \n",
    "2b) numbers (eliminate numbers and words with numbers)  \n",
    "3) all to lower  \n",
    "4) accents? (amb unidecode, pero passa √ß a c, √± a n, aixo introdueix errors?)  \n",
    "5) i is fessim una columna amb 0-1 indicant si hi ha emoji? (sigui com sigui, pero algu potser els fa servir bastant?)\n",
    "6) segurament, si hi ha hashtag del partit l'ha posat el mateix partit (publicitat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>username</th>\n",
       "      <th>party</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>martarovira</td>\n",
       "      <td>erc</td>\n",
       "      <td>√öltim acte de campanya! Aqu√≠ tossudament al√ßat...</td>\n",
       "      <td>2017-12-19 20:12:01</td>\n",
       "      <td>785</td>\n",
       "      <td>2295</td>\n",
       "      <td>√∫ltim acte de campanya aqu√≠ tossudament al√ßats...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>xavierdomenechs</td>\n",
       "      <td>comuns</td>\n",
       "      <td>#Badalona necessita uns pressupostos que posin...</td>\n",
       "      <td>2018-04-27 10:04:19</td>\n",
       "      <td>55</td>\n",
       "      <td>93</td>\n",
       "      <td>badalona necessita uns pressupostos que posin ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>albert_rivera</td>\n",
       "      <td>cs</td>\n",
       "      <td>Encuentro Villac√≠s-Valls para lanzar una estra...</td>\n",
       "      <td>2018-11-17 20:34:58</td>\n",
       "      <td>357</td>\n",
       "      <td>622</td>\n",
       "      <td>encuentro villac√≠s-valls para lanzar una estra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>jaumecollboni</td>\n",
       "      <td>psc</td>\n",
       "      <td>‚ÄúLa palabra es como una bala, no tiene retorno...</td>\n",
       "      <td>2018-10-22 18:10:01</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>‚Äúla palabra es como una bala no tiene retorno‚Äù...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>albiol_xg</td>\n",
       "      <td>ppc</td>\n",
       "      <td>üìª Esta noche, a partir de las 22:10h, me entre...</td>\n",
       "      <td>2018-08-16 10:30:27</td>\n",
       "      <td>20</td>\n",
       "      <td>47</td>\n",
       "      <td>esta noche partir de las  me entrevistan en l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id         username   party  \\\n",
       "0   0      martarovira     erc   \n",
       "1   1  xavierdomenechs  comuns   \n",
       "2   2    albert_rivera      cs   \n",
       "3   3    jaumecollboni     psc   \n",
       "4   4        albiol_xg     ppc   \n",
       "\n",
       "                                                text          created_at  \\\n",
       "0  √öltim acte de campanya! Aqu√≠ tossudament al√ßat... 2017-12-19 20:12:01   \n",
       "1  #Badalona necessita uns pressupostos que posin... 2018-04-27 10:04:19   \n",
       "2  Encuentro Villac√≠s-Valls para lanzar una estra... 2018-11-17 20:34:58   \n",
       "3  ‚ÄúLa palabra es como una bala, no tiene retorno... 2018-10-22 18:10:01   \n",
       "4  üìª Esta noche, a partir de las 22:10h, me entre... 2018-08-16 10:30:27   \n",
       "\n",
       "   retweet_count  favorite_count  \\\n",
       "0            785            2295   \n",
       "1             55              93   \n",
       "2            357             622   \n",
       "3              4               6   \n",
       "4             20              47   \n",
       "\n",
       "                                          text_clean  \n",
       "0  √∫ltim acte de campanya aqu√≠ tossudament al√ßats...  \n",
       "1  badalona necessita uns pressupostos que posin ...  \n",
       "2  encuentro villac√≠s-valls para lanzar una estra...  \n",
       "3  ‚Äúla palabra es como una bala no tiene retorno‚Äù...  \n",
       "4   esta noche partir de las  me entrevistan en l...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['text_clean'] = [filter_symb1(filter_symb_hashtag(filter_single(eliminate_emojiis(eliminate_numbers(lower_text(row['text'])))))) for index, row in train_df.iterrows()]\n",
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ÄúEstas son las reglas del juego en nuestro Estado de Derecho y en nuestra democracia‚Äù (Lesmes) la clave aqu√≠ est√° en la palabra \"nuestro\", \"nuestro Estado\" \n",
      "‚Äúestas son las reglas del juego en nuestro estado de derecho en nuestra democracia‚Äù lesmes la clave aqu√≠ est√° en la palabra nuestro nuestro estado\n"
     ]
    }
   ],
   "source": [
    "print (train_df.text[12])\n",
    "print (train_df.text_clean[12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Afegim una columna amb idioma\n",
    "tot i que alguns resultats ens han mostrat pitjors scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>username</th>\n",
       "      <th>party</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>language</th>\n",
       "      <th>lang_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>martarovira</td>\n",
       "      <td>erc</td>\n",
       "      <td>√öltim acte de campanya! Aqu√≠ tossudament al√ßat...</td>\n",
       "      <td>2017-12-19 20:12:01</td>\n",
       "      <td>785</td>\n",
       "      <td>2295</td>\n",
       "      <td>√∫ltim acte de campanya aqu√≠ tossudament al√ßats...</td>\n",
       "      <td>ca</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>xavierdomenechs</td>\n",
       "      <td>comuns</td>\n",
       "      <td>#Badalona necessita uns pressupostos que posin...</td>\n",
       "      <td>2018-04-27 10:04:19</td>\n",
       "      <td>55</td>\n",
       "      <td>93</td>\n",
       "      <td>badalona necessita uns pressupostos que posin ...</td>\n",
       "      <td>ca</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>albert_rivera</td>\n",
       "      <td>cs</td>\n",
       "      <td>Encuentro Villac√≠s-Valls para lanzar una estra...</td>\n",
       "      <td>2018-11-17 20:34:58</td>\n",
       "      <td>357</td>\n",
       "      <td>622</td>\n",
       "      <td>encuentro villac√≠s-valls para lanzar una estra...</td>\n",
       "      <td>es</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>jaumecollboni</td>\n",
       "      <td>psc</td>\n",
       "      <td>‚ÄúLa palabra es como una bala, no tiene retorno...</td>\n",
       "      <td>2018-10-22 18:10:01</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>‚Äúla palabra es como una bala no tiene retorno‚Äù...</td>\n",
       "      <td>es</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>albiol_xg</td>\n",
       "      <td>ppc</td>\n",
       "      <td>üìª Esta noche, a partir de las 22:10h, me entre...</td>\n",
       "      <td>2018-08-16 10:30:27</td>\n",
       "      <td>20</td>\n",
       "      <td>47</td>\n",
       "      <td>esta noche partir de las  me entrevistan en l...</td>\n",
       "      <td>es</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id         username   party  \\\n",
       "0   0      martarovira     erc   \n",
       "1   1  xavierdomenechs  comuns   \n",
       "2   2    albert_rivera      cs   \n",
       "3   3    jaumecollboni     psc   \n",
       "4   4        albiol_xg     ppc   \n",
       "\n",
       "                                                text          created_at  \\\n",
       "0  √öltim acte de campanya! Aqu√≠ tossudament al√ßat... 2017-12-19 20:12:01   \n",
       "1  #Badalona necessita uns pressupostos que posin... 2018-04-27 10:04:19   \n",
       "2  Encuentro Villac√≠s-Valls para lanzar una estra... 2018-11-17 20:34:58   \n",
       "3  ‚ÄúLa palabra es como una bala, no tiene retorno... 2018-10-22 18:10:01   \n",
       "4  üìª Esta noche, a partir de las 22:10h, me entre... 2018-08-16 10:30:27   \n",
       "\n",
       "   retweet_count  favorite_count  \\\n",
       "0            785            2295   \n",
       "1             55              93   \n",
       "2            357             622   \n",
       "3              4               6   \n",
       "4             20              47   \n",
       "\n",
       "                                          text_clean language  lang_val  \n",
       "0  √∫ltim acte de campanya aqu√≠ tossudament al√ßats...       ca         1  \n",
       "1  badalona necessita uns pressupostos que posin ...       ca         1  \n",
       "2  encuentro villac√≠s-valls para lanzar una estra...       es         0  \n",
       "3  ‚Äúla palabra es como una bala no tiene retorno‚Äù...       es         0  \n",
       "4   esta noche partir de las  me entrevistan en l...       es         0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Translate text to spanish and define column (vector) with language (spa:0, cat:1)\n",
    "#!pip install langdetect\n",
    "from langdetect import detect \n",
    "train_df['language'] = [detect(row['text']) for index, row in train_df.iterrows()]\n",
    "\n",
    "# language column to 1-0 --> esta columna lang_val la ponemos al final del array (Xvec)\n",
    "train_df['lang_val'] = np.where(train_df.language == 'ca', 1, 0)\n",
    "train_df.head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### coses per fer:\n",
    "- lemmatization: sino ho podem traduir (el googletranslator dona problemes) no el podem aplicar (no n'hi ha en catala)  \n",
    "- identificar hastags? ara per ara han quedat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "Ho fem fent servir el pipeline (aixo ens permet aplicar una funcio per buscar parametres optims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "### Resultats\n",
    "1.  \n",
    "2.  score = . Eliminant simbol hashtag  \n",
    "\n",
    "3.  score =0.66 . eliminant emojis. No ens movem d'aqui, amb 10^3 estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pablo/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['aren', 'can', 'couldn', 'des', 'didn', 'doesn', 'don', 'hadn', 'hasn', 'haven', 'isn', 'let', 'll', 'mustn', 're', 'shan', 'shouldn', 've', 'wasn', 'weren', 'won', 'wouldn'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score = 0.64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_df['text_clean'], train_df['party'].values, test_size=0.20, random_state=345 )\n",
    "vectorizer= TfidfVectorizer(min_df=1, ngram_range=(1,3), max_features=12000, stop_words=stop_words())\n",
    "\n",
    "Xvec=vectorizer.fit_transform(X_train).toarray()\n",
    "Xvec_test=vectorizer.transform(X_test).toarray()\n",
    "\n",
    "\n",
    "clf.fit(Xvec,y_train)\n",
    "clf.predict(Xvec_test)\n",
    "\n",
    "print (\"score = %3.2f\" %(clf.score(Xvec_test,y_test)) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
